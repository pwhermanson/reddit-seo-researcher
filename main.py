""# ===============================================
# Project: Reddit SEO Researcher
#
# Project Structure:
# reddit-seo-researcher/
# â”‚â”€â”€ main.py  # âœ… Parent script that calls all modules
# â”‚â”€â”€ scraper.py  # âœ… Website scraping functions
# â”‚â”€â”€ openai_analysis.py  # âœ… OpenAI API interactions
# â”‚â”€â”€ google_sheets.py  # âœ… Google Sheets authentication & writing functions
# â”‚â”€â”€ utils.py  # âœ… Helper functions (like text formatting)
# â”‚â”€â”€ requirements.txt  # âœ… List of required Python packages
# ===============================================

import re
import scraper
import openai_analysis
import google_sheets
import sys

# âœ… Get Target Website from GitHub Actions Input
if len(sys.argv) < 2:
    print("âŒ Error: No target website provided.")
    exit(1)

target_website = sys.argv[1].strip()

# âœ… Remove 'https://' or 'http://' for clean filename use
clean_target_website = re.sub(r"https?://", "", target_website)

# âœ… Ensure 'https://' is included for requests (scraping & API calls)
if not target_website.startswith(("http://", "https://")):
    target_website = f"https://{target_website}"

print(f"ðŸ” Using cleaned filename: {clean_target_website}")
print(f"ðŸ” Using full URL for requests: {target_website}")

# âœ… Authenticate Google Sheets
client = google_sheets.authenticate_google_sheets()

# âœ… Debugging: List all available spreadsheets
print("ðŸ” Available Google Sheets:")
for sheet in client.openall():
    print(f"- {sheet.title}")

# âœ… Attempt to open the correct spreadsheet
spreadsheet_name = f"Reddit SEO Research | {clean_target_website}"
try:
    spreadsheet = client.open(spreadsheet_name)
    print(f"âœ… Successfully opened: {spreadsheet_name}")
except gspread.exceptions.SpreadsheetNotFound:
    print(f"âŒ Error: Google Sheet '{spreadsheet_name}' not found.")
    print("ðŸ“Œ Ensure the sheet exists and the service account has Editor access.")
    exit(1)

# âœ… Scrape Website
scraped_text = scraper.scrape_target_website(target_website)

# âœ… Analyze with OpenAI
industry_summary = openai_analysis.analyze_with_openai(scraped_text)

# âœ… Store in Google Sheets
google_sheets.add_industry_tab(spreadsheet, industry_summary, analyzed_pages)

# âœ… Fetch Relevant Subreddits
subreddits = openai_analysis.get_relevant_subreddits(industry_summary)
google_sheets.add_subreddit_tab(spreadsheet, subreddits)

print("âœ… Process completed successfully!")


